#  2.Create Airlow DAG example Guide

```bash
cd /data/airflow
mkdir dags
cd dags
```

### 1、create Hello World DAG

```
from datetime import timedelta, datetime
import airflow
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator

default_args = { #default parameters
    'depends_on_past': False,  #Whether to depend on upstream tasks
    'start_date': datetime(2018, 5, 2), #Task start time, default utc time
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'hello_world_dag',  #dag id
    default_args=default_args,
    description='my first DAG', #description
    schedule='*/25 * * * *', # crontab
    start_date=datetime(2018, 5, 28) #start time，override default parameters
)

def print_hello():
    return 'Hello world!'

dummy_operator = EmptyOperator(task_id='dummy_task', dag=dag)

hello_operator = BashOperator(   #Define the task of executing bash commands through BashOperator
    task_id='sleep_task',
    depends_on_past=False,
    bash_command='echo `date` >> /home/test.txt',
    dag=dag
)

dummy_operator >> hello_operator #Set task dependencies
#dummy_operator.set_downstream(hello_operator)
```

get by variable

```
from airflow.models import  Variable

default_args = { #default parameters
    'depends_on_past': False,  
    'start_date': datetime(2018, 5, 2), 
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'hello_world_dag', 
    default_args=default_args,
    description='my first DAG', 
    schedule='*/25 * * * *', # crontab
    start_date=datetime(2018, 5, 28)
)

def read_variable():
    strInfo = Variable.get("strInfo")
    jsonInfo = Variable.get("jsonInfo")
    
    print(strInfo,jsonInfo)
```

Trigger DAG w/config

```
from datetime import timedelta, datetime
import airflow
from airflow import DAG
from airflow.operators.bash import BashOperator
from airflow.operators.empty import EmptyOperator
from airflow.operators.python  import PythonOperator
from airflow.models import  Variable

default_args = { 
    'depends_on_past': False,  
    'start_date': datetime(2018, 5, 2),
    'email_on_failure': False,
    'email_on_retry': False,
    'retries': 1,
    'retry_delay': timedelta(minutes=5),
}

dag = DAG(
    'hello_dag',  
    default_args=default_args,
    description='my first DAG',
    start_date=datetime(2018, 5, 28)
)

def read_variable():
    strInfo = Variable.get("strInfo")
    jsonInfo = Variable.get("jsonInfo")
    
    print(strInfo,jsonInfo)


def print_hello(**context):
    context_var = context["dag_run"].conf.get("context_var")
    print(context_var)
    return 'Hello world!'

dummy_operator = EmptyOperator(task_id='dummy_task', dag=dag)

python_operator = PythonOperator(task_id='python_task',python_callable=print_hello,dag = dag,provide_context=True)


dummy_operator >> python_operator 
#dummy_operator.set_downstream(hello_operator)
```

