# 1. **Install and deploy Airflow Guide**

**Note：When deploying services, it is best to use the root user to install and deploy.**

### 1. **Install anaconda-tools**

```bash
# The aws default data disk is mounted in the /data directory, please install and deploy in this directory

cd /data
# Download the installation script
wget <https://mirrors.bfsu.edu.cn/anaconda/archive/Anaconda3-2022.10-Linux-x86_64.sh> --no-check-certificate
# Execute the installation script
bash Anaconda3-2022.10-Linux-x86_64.sh
```

### 2. **Add anaconda environment variable**

```bash
# When installing with the root user, the default path of conda is /root/anaconda3/bin
vim ~/.bashrc
export PATH="/root/anaconda3/bin:$PATH"
source ~/.bashrc
```

### 3. **Create a python virtual environment**

```bash
# Create airflow python virtual environment
conda create -n  airflow python=3.10
# Activate the airflow python virtual environment
conda activate airflow
```

### 4.**Create airflow installation directory**

```jsx
mkdir /data/airflow
```

### 5.**Set related environment variables**

```bash
# setup temporary environment
export AIRFLOW_HOME=/data/airflow

# setup permanent environment
vim /etc/environment
AIRFLOW_HOME=/data/airflow

# system manage airfow service
vim /etc/default/airflow
AIRFLOW_HOME=/data/airflow
```

### 6. **install airflow**

```bash
# Install using pip

cd /data/airflow

AIRFLOW_VERSION=2.5.2
PYTHON_VERSION="$(python3 --version | cut -d " " -f 2 | cut -d "." -f 1-2)"
CONSTRAINT_URL="<https://raw.githubusercontent.com/apache/airflow/constraints-${AIRFLOW_VERSION}/constraints-${PYTHON_VERSION}.txt>"

apt install python3-pip
pip install "apache-airflow==${AIRFLOW_VERSION}" --constraint "${CONSTRAINT_URL}"
pip install mysql-connector-python  docker 
pip install apache-airflow-providers-docker
apt install mysql-client-core-8.0
```

### 7.**Install docker-compose**

**The default database of airflow is not mysql, so you need to change the database configuration and install the mysql service**

**The official installation link**： https://docs.docker.com/compose/install/other/

```bash
# Create airflow mysql database directory
mkdir -p /data/airflow/mysql/{data,config}

cd /data/airflow/mysql/

# install docker-compose
# Note: There may be problems with apt installation, it is recommended to use the following methods to install

curl -SL <https://github.com/docker/compose/releases/download/v2.17.2/docker-compose-linux-x86_64> -o /usr/local/bin/docker-compose

ln -s /usr/local/bin/docker-compose /usr/bin/docker-compose

docker-compose version
```

**Edit the mysql docker-compose.yaml file as follows:**

```bash
vim docker-compose.yaml
version: "3"
services: 
 db:
  restart: always
  container_name: airflow_mysql
  command: 
   --lower_case_table_names=1
   --character-set-server=utf8mb4
   --collation-server=utf8mb4_general_ci
   --explicit_defaults_for_timestamp=true
  image: mysql:5.7
  environment:
   TZ: Asia/Shanghai
   MYSQL_ROOT_PASSWORD: airflow
   MYSQL_DATABASE: airflow
  ports:
   - 3306:3306
  volumes: 
   - /data/airflow/mysql/data:/var/lib/mysql
   - /data/airflow/mysql/config:/etc/mysql/conf.d
docker-compose up  -d
```

![1](C:\Users\cn200198165\Desktop\daimler\assets\1.png)

![1](1. Install and deploy Airflow Guide.assets/1.png)



### 7.**Initialize airflow to generate airflow.cfg file and create login user**

```bash
# Initialize airflow db to generate airflow.cfg configuration file

airflow db init
```

![2](1. Install and deploy Airflow Guide.assets/2.png)

```bash
# Create a user, enter the password according to the prompt
airflow users create \\
    --username admin \\
    --firstname airflow \\
    --lastname airflow \\
    --role Admin \\
    --email spiderman@superhero.org
```

![3](1. Install and deploy Airflow Guide.assets/3.png)

### 8. **Change the airflow.cfg configuration file**

```bash
vim  /data/airflow/airflow.cfg
# Change the following parameters

executor = LocalExecutor
sql_alchemy_conn = mysql+mysqlconnector://root:airflow@127.0.0.1:3306/airflow
load_examples = False
# After changing the configuration, execute the following command again
airflow db init
```

![4](1. Install and deploy Airflow Guide.assets/4.png)

**If Trouble-shooting reports an error:**

![5](1. Install and deploy Airflow Guide.assets/5.png)

**docker ps to see if sql is pulled up:**

![6](1. Install and deploy Airflow Guide.assets/6.png)

**Connect locally: mysql -h127.0.0.1 (or local ip of ifconfig) -uroot -p**

![7](1. Install and deploy Airflow Guide.assets/7.png)

**There is a high probability that there is a problem with the path of volumes in /data/airflow/mysql/docker-compose.yaml, go to check. If the path is wrong, restart docker-compose up -d after changing yaml**

### 9. **Create airflow startup service**

```bash
vim /lib/systemd/system/airflow-scheduler.service

[Unit]
Description=Airflow webserver daemon
After=network.target postgresql.service mysql.service redis.service rabbitmq-server.service

[Service]
EnvironmentFile=/etc/default/airflow
PIDFile=/data/airflow/airflow-scheduler.pid
Type=simple
ExecStart=/root/anaconda3/envs/airflow/bin/airflow  scheduler  --pid /data/airflow/airflow-scheduler.pid 
Restart=on-failure
RestartSec=5s
PrivateTmp=true

[Install]
WantedBy=multi-user.target
vim /lib/systemd/system/airflow-webserver.service

[Unit]
Description=Airflow webserver daemon
After=network.target postgresql.service mysql.service redis.service rabbitmq-server.service

[Service]
EnvironmentFile=/etc/default/airflow
PIDFile=/data/airflow/airflow-webserver.pid
Type=simple
ExecStart=/root/anaconda3/envs/airflow/bin/airflow  webserver -p 18080  --pid  /data/airflow/airflow-webserver.pid 
Restart=on-failure
RestartSec=5s
PrivateTmp=true

[Install]
WantedBy=multi-user.target
```

### 10. **Restart the airflow service**

```
systemctl daemon-reload

systemctl enable airflow-webserver && systemctl start airflow-webserver
systemctl enable airflow-scheduler  && systemctl start airflow-scheduler
```

![8](1. Install and deploy Airflow Guide.assets/8.png)





